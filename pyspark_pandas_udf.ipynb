{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#Need to set environment variables in order to make pyspark work in Python3.6\n",
    "spark_home=os.environ['SPARK_HOME']\n",
    "os.environ['PYTHONPATH']= spark_home+\"/python/lib/py4j-0.10.4-src.zip\"\n",
    "os.environ['PYSPARK_PYTHON']=\"/dfm0/util/dfm_python/python36/bin/python3.6\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']=\"/dfm0/util/dfm_python/python36/bin/python3.6\"\n",
    "\n",
    "super_dir='/dfm1/lijli06/DFM_SPARK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "            .master('local[5]') \\\n",
    "            .appName(\"local_test\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = \"hdfs://dfm-cluster/DFM/sysauditlog/2018/08/01/sysauditlog.avro\"\n",
    "tmp_df = spark.read.format(\"com.databricks.spark.avro\").load(tmp_path)\n",
    "tmp_df = tmp_df.withColumn('DATELOGGED', F.from_utc_timestamp('DATELOGGED', 'UTC')) \\\n",
    "               .withColumn('DATE', F.to_date('DATELOGGED'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pandas UDF for datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf('string', F.PandasUDFType.SCALAR)\n",
    "def get_hour_str(s):\n",
    "    return s.dt.strftime('%H:00:00')\n",
    "# get_hour_str_udf = F.pandas_udf(get_hour_str, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tmp_df.select('ORGNAME', 'DATELOGGED').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19:00:00\n",
       "1    19:00:00\n",
       "2    06:00:00\n",
       "3    06:00:00\n",
       "4    00:00:00\n",
       "5    00:00:00\n",
       "6    00:00:00\n",
       "7    19:00:00\n",
       "8    19:00:00\n",
       "9    06:00:00\n",
       "Name: DATELOGGED, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hour_str.func(df.DATELOGGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|         DATELOGGED|    HOUR|\n",
      "+-------------------+--------+\n",
      "|2018-08-01 19:03:02|19:00:00|\n",
      "|2018-08-01 19:03:21|19:00:00|\n",
      "|2018-08-01 06:45:31|06:00:00|\n",
      "|2018-08-01 06:45:37|06:00:00|\n",
      "|2018-08-01 00:16:38|00:00:00|\n",
      "|2018-08-01 00:17:08|00:00:00|\n",
      "|2018-08-01 00:17:10|00:00:00|\n",
      "|2018-08-01 19:06:14|19:00:00|\n",
      "|2018-08-01 19:06:18|19:00:00|\n",
      "|2018-08-01 06:45:43|06:00:00|\n",
      "+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_df.select('DATELOGGED').limit(10) \\\n",
    "      .withColumn('HOUR', get_hour_str('DATELOGGED')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Pandas UDF for Country (string) Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fibin_country = pd.read_csv(os.path.join(super_dir, 'extn_hashes/homer_country_map.csv'),header=0, keep_default_na=False)\n",
    "fibin_country1 = fibin_country[fibin_country['FIBIN']!='all'].copy()\n",
    "fibin_country1['ORGNAME'] = fibin_country1['ORGNAME']+'@'+fibin_country1['FIBIN']\n",
    "fibin_country1 = dict(fibin_country1[['ORGNAME', 'ISSUERCOUNTRY']].values)\n",
    "fibin_country2 = fibin_country[fibin_country['FIBIN']=='all'].copy()\n",
    "fibin_country2 = dict(fibin_country2[['ORGNAME', 'ISSUERCOUNTRY']].values)\n",
    "dicts = {**fibin_country1, **fibin_country2}\n",
    "def update_issuer_country(c1, c2, dicts=dicts):\n",
    "    up1 = (c1 + '@' + c2).replace(dicts)\n",
    "    up2 = c1.replace(dicts)\n",
    "    up2[up2==c1]=''\n",
    "    up1[up1.str.contains('@')] = up2[up1.str.contains('@')]\n",
    "\n",
    "    return up1\n",
    "update_issuer_country_udf = F.pandas_udf(update_issuer_country, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|ISSUERCOUNTRY|\n",
      "+-------------+\n",
      "|          826|\n",
      "|          826|\n",
      "|          826|\n",
      "|          826|\n",
      "|          826|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_df.select('ISSUERCOUNTRY').limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|    NewCountry|\n",
      "+--------------+\n",
      "|United Kingdom|\n",
      "|United Kingdom|\n",
      "|United Kingdom|\n",
      "|United Kingdom|\n",
      "|United Kingdom|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_df.select(update_issuer_country_udf(F.col('ORGNAME'), F.col('FIBIN')).alias('NewCountry')).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Pandas UDF Median on Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_field = 'DATE'\n",
    "pivot_field = 'ORGNAME'\n",
    "weight_field = 'AMOUNTUSD'\n",
    "schema = tmp_df.select(group_field, pivot_field, weight_field).schema\n",
    "\n",
    "@F.pandas_udf(schema, F.PandasUDFType.GROUPED_MAP)\n",
    "def median_amt(amt_df):\n",
    "    group = amt_df[group_field].iloc[0]\n",
    "    pivot = amt_df[pivot_field].iloc[0]\n",
    "    return pd.DataFrame([[group, pivot, amt_df[weight_field].median()]], columns=[group_field, pivot_field, weight_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tmp_df.select(['DATE', 'AMOUNTUSD']).limit(50).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>AMOUNTUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>642.004888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>39.731120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>314.584340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>91.687200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>56.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>100.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>64.597800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>138.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>9.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>11.010825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>7.188565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>136.947336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>4.778848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>6.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>73.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>310.625120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2094.024696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>118.707140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>118.707140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>41.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>32.868472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>10.941375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>13.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>19.170960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>250.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>351.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>340.090052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>22.505040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>503.130936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>144.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>0.447706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>400.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>15.753528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>92.395692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>6.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>59.735600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>18.351375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>29.159308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>209.074600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>7.877880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>4.167600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>51.400400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>106.690560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>13.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>27.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>44.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>11.471499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>95.160200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE    AMOUNTUSD\n",
       "0   2018-08-01   642.004888\n",
       "1   2018-08-01     0.000000\n",
       "2   2018-08-01    39.731120\n",
       "3   2018-08-01   314.584340\n",
       "4   2018-08-01    91.687200\n",
       "5   2018-08-01   480.000000\n",
       "6   2018-08-01    56.500000\n",
       "7   2018-08-01   100.022400\n",
       "8   2018-08-01    64.597800\n",
       "9   2018-08-01   138.920000\n",
       "10  2018-08-01     9.029800\n",
       "11  2018-08-01    11.010825\n",
       "12  2018-08-01     7.188565\n",
       "13  2018-08-01   136.947336\n",
       "14  2018-08-01     4.778848\n",
       "15  2018-08-01     6.946000\n",
       "16  2018-08-01    73.627600\n",
       "17  2018-08-01   310.625120\n",
       "18  2018-08-01  2094.024696\n",
       "19  2018-08-01   118.707140\n",
       "20  2018-08-01   118.707140\n",
       "21  2018-08-01    41.676000\n",
       "22  2018-08-01    32.868472\n",
       "23  2018-08-01    10.941375\n",
       "24  2018-08-01    13.892000\n",
       "25  2018-08-01    19.170960\n",
       "26  2018-08-01   250.056000\n",
       "27  2018-08-01   351.467600\n",
       "28  2018-08-01   340.090052\n",
       "29  2018-08-01    22.505040\n",
       "30  2018-08-01   503.130936\n",
       "31  2018-08-01   144.150000\n",
       "32  2018-08-01     0.447706\n",
       "33  2018-08-01   400.089600\n",
       "34  2018-08-01    15.753528\n",
       "35  2018-08-01    92.395692\n",
       "36  2018-08-01     6.946000\n",
       "37  2018-08-01    59.735600\n",
       "38  2018-08-01    18.351375\n",
       "39  2018-08-01    29.159308\n",
       "40  2018-08-01   209.074600\n",
       "41  2018-08-01     7.877880\n",
       "42  2018-08-01     4.167600\n",
       "43  2018-08-01    51.400400\n",
       "44  2018-08-01   106.690560\n",
       "45  2018-08-01    13.892000\n",
       "46  2018-08-01    27.784000\n",
       "47  2018-08-01    44.950000\n",
       "48  2018-08-01    11.471499\n",
       "49  2018-08-01    95.160200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.1 s ± 186 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tmp_df.select(['DATE', 'ORGNAME', 'AMOUNTUSD']).groupBy([group_field, pivot_field]).apply(median_amt).rdd.map(list).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use percentile_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = F.expr('percentile_approx(AMOUNTUSD, 0.5, 800)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.8 s ± 244 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tmp_df.select(['DATE', 'ORGNAME', 'AMOUNTUSD']).groupBy([group_field, pivot_field]).agg(agg_func).rdd.map(list).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Pandas UDF for Date Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date(2018, 8, 1)\n",
    "def date_map(s, start_date, interval=2, unit='months'):\n",
    "    if unit.lower()=='days':\n",
    "        delta = s - start_date        \n",
    "        interval = delta.astype(\"timedelta64[D]\")//interval*interval\n",
    "        o = pd.to_datetime(s)\n",
    "        o[:] = start_date\n",
    "        o = o + interval.astype(\"timedelta64[D]\")\n",
    "    elif unit.lower()=='months':\n",
    "        start_date = start_date + relativedelta(day=1)\n",
    "        s = pd.to_datetime(s)\n",
    "        o = s.copy()\n",
    "        o[:] = start_date\n",
    "        delta = s.dt.to_period('M') - o.dt.to_period('M')\n",
    "        interval = delta//interval*interval\n",
    "        o = o + interval.astype('timedelta64[M]') + pd.offsets.MonthBegin(n=0)\n",
    "    else:\n",
    "        start_date = start_date + relativedelta(month=1, day=1)\n",
    "        s = pd.to_datetime(s)\n",
    "        o = s.copy()\n",
    "        o[:] = start_date\n",
    "        delta = s.dt.to_period('Y') - o.dt.to_period('Y')\n",
    "        interval = delta//interval*interval\n",
    "        o = o + interval.astype('timedelta64[Y]') + pd.offsets.YearBegin(n=0)\n",
    "        \n",
    "    return o.dt.date\n",
    "\n",
    "date_map_udf = F.pandas_udf(lambda s, start_date=start_date: date_map(s, start_date), returnType=DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date\n",
       "0   1  2018-08-04\n",
       "1   2  2019-11-10\n",
       "2   2  2022-12-21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, date(2018, 8, 4)], [2, date(2019, 11, 10)], [2, date(2022, 12, 21)]], columns=['id', 'date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2018-08-01\n",
       "1    2019-10-01\n",
       "2    2022-12-01\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_map_udf.func(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|         DATELOGGED|      DATE|\n",
      "+-------------------+----------+\n",
      "|2018-08-01 19:03:02|2018-08-01|\n",
      "|2018-08-01 19:03:21|2018-08-01|\n",
      "|2018-08-01 06:45:31|2018-08-01|\n",
      "|2018-08-01 06:45:37|2018-08-01|\n",
      "|2018-08-01 00:16:38|2018-08-01|\n",
      "|2018-08-01 00:17:08|2018-08-01|\n",
      "|2018-08-01 00:17:10|2018-08-01|\n",
      "|2018-08-01 19:06:14|2018-08-01|\n",
      "|2018-08-01 19:06:18|2018-08-01|\n",
      "|2018-08-01 06:45:43|2018-08-01|\n",
      "|2018-08-01 06:44:53|2018-08-01|\n",
      "|2018-08-01 00:17:15|2018-08-01|\n",
      "|2018-08-01 00:17:22|2018-08-01|\n",
      "|2018-08-01 19:08:56|2018-08-01|\n",
      "|2018-08-01 19:09:01|2018-08-01|\n",
      "|2018-08-01 06:44:55|2018-08-01|\n",
      "|2018-08-01 06:44:55|2018-08-01|\n",
      "|2018-08-01 00:17:22|2018-08-01|\n",
      "|2018-08-01 00:16:30|2018-08-01|\n",
      "|2018-08-01 19:09:55|2018-08-01|\n",
      "+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_df.select('DATELOGGED','DATE').limit(50).withColumn('DATE', date_map_udf('DATE')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
